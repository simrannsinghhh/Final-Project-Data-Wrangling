# -*- coding: utf-8 -*-
"""Covid_Analysis_Capstone_Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mrNoZumAPoSUcTZBl4rMTR9K1k0MoHb4
"""

import pandas as pd

url= 'https://raw.githubusercontent.com/SR1608/Datasets/main/covid-data.csv'

data = pd.read_csv(url)



#1.HIGH LEVEL DATA UNDERTANDING#

#A. Find the no. of rows and columns in a dataset

num_rows, num_columns = data.shape

print(f"The number of rows in the dataset is: {num_rows}")
print(f"The number of columns in the dataset is: {num_columns}")

#B. Data types of columns and names

print("Data types of columns:")
print(data.dtypes)

print("\nColumn names:")
print(data.columns)

#B.Info and describe of data in dataframe

data.info()

data.describe()

#3.LOW LEVEL DATA UNDERSTANDING

#A.Find count of unique values in location column.

data['location'].nunique()

#B.Find which continent has maximum frequency using values counts

data['continent'].value_counts()

#C.Find maximum and mean value in "total_cases"

data['total_cases'].max()

data['total_cases'].mean()

#D. Find 25%,50%,75% quartile value in 'total_Deaths'

data['total_deaths'].quantile([0.25, 0.5, 0.75])

#E. Find which continent has maximum 'human_development_index'

data.loc[data.groupby('continent')['human_development_index'].idxmax()]

#F: Find which continent has minimum "gdp_per_capita"

data.loc[data.groupby('continent')['gdp_per_capita'].idxmin()]

#4. Filter the data with only this columns['continent','location','date',total_cases','total_deaths','gdp_per_capita','human_Development_index']and update the data frame.

columns_s = ['continent', 'location', 'date', 'total_cases', 'total_deaths', 'gdp_per_capita', 'human_development_index']

data.filter(columns_s)

#5. Data Clenaning

#A. Remove all duplicates observations

data.drop_duplicates()

#B. Find missing values in All columns

data.isnull().sum()

#C. Remove all observations where continent column value is missing

data.dropna(subset=['continent'])

#D. Fill all missing values with 0

data.fillna(0)

#6. DATE TIME FORMAT

#A.Convert date column in datetime format using pandas.to_datetime

data['date'] = pd.to_datetime(data['date'])
print(data)

#B.Create new column month after extracting month data from date column.

data['month'] = data['date'].dt.month
print(data)

#7. DATA AGGREGATION

#A. Find max value in all columns using groupby function on 'continent' column

max_values_by_continent = data.groupby('continent').max().reset_index()

print("Maximum values in all columns by continent:")
print(max_values_by_continent)

#B. Store the result into a new data frame named 'df_groupby'.

df_groupby = data.groupby('continent').max().reset_index()

print(df_groupby)

#8. FEATURE ENGINEERING:

#A. Create a new feature 'total_Deaths_to_total_cases' by ratio of 'total_Deaths' column to 'total_Cases'.

data['total_Deaths_to_total_cases'] = data['total_deaths'] / data['total_cases']

print(data['total_Deaths_to_total_cases'])

#9. Data Visualization

#A.Perform univariate analysis on 'gdp_per_capita' column by plotting histogram using seaborn dist plot.

data.gdp_per_capita

pip install seaborn matplotlib

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

plt.figure(figsize=(5,3))
sns.histplot(data=data, x='gdp_per_capita')
plt.title('Histogram of GDP per Capita')
plt.xlabel('GDP per Capita')
plt.ylabel('Frequency')
plt.show()

#B. Plot a scatter plot of 'total_cases' & 'gdp_per_capita'

plt.figure(figsize=(8,7))
plt.scatter(data['total_cases'], data['gdp_per_capita'])
plt.title('Scatter Plot of Total Cases vs GDP per Capita')
plt.xlabel('Total Cases')
plt.ylabel('GDP per Capita')
plt.show()

#c. Plot Pairplot on df_groupby dataset.

#. not running...

#D. Plot a bar plot of 'continent' column with 'total_cases'.

df = pd.DataFrame(data)


plt.figure(figsize=(8, 6))
sns.barplot(x='continent', y='total_cases', data=df)
plt.title('Total Cases per Continent')
plt.xlabel('Continent')
plt.ylabel('Total Cases')
plt.show()

#10. Save the df_groupby dataframe in your local drive using pandas.to_csv function.

df_groupby = pd.DataFrame(data)

df_groupby.to_csv('df_groupby.csv', index=False)